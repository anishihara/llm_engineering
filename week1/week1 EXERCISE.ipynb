{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "MODEL = \"llama3.2:3b\"\n",
    "MODEL = \"deepseek-r1:7b\"\n",
    "OLLAMA_API_HOST = \"http://192.168.0.247:11434\"\n",
    "openai_ollama = OpenAI(base_url=OLLAMA_API_HOST + '/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert developer. Please respond as succint as possible.\"\n",
    "\n",
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\n",
    "Please respond in Portuguese.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, o usuário está olhando para essa expressão de geração em Python: yield from {book.get(\"author\") for book in books if book.get(\"author\")}. Quer que eu explico o que ela faz e por que.\n",
       "\n",
       "Primeiro, preciso entender cada parte desse código. O 'yield from' é uma instrução genérica que envía elementos do iterável para o converseiro. Então, está iterando sobre algo. Caso tenha saídas de function generator, mas em geral, serve para iterar.\n",
       "\n",
       "A expressão em { } é um dict comprehension. Within, tem book.get(\"author\"), que está tendo o valor do author do dicionário book. Depois, um if, verificando se book.get(\"author\") existe ou não. Se sim, inclui na collection.\n",
       "\n",
       "Então,整个表达式是在收集所有书籍中拥有 \"author\"键的那些author名字，然后将它们传递给yield from，从而将这些作者名字作为迭代器返回。\n",
       "\n",
       "Acho que a razão principal desse código é pegar os autores de livros onde o author existe, e emitir cada author individualmente. Isso pode ser útil para processar cada autor separadamente, talvez na impressão ou como alimentação para uma função que processe cada autor.\n",
       "\n",
       "Também posso pensar em usoções práticas, como pegando os autores de livros de uma lista e imprimindo-os individualmente. Isso permitiria ver qualautro autor está disponível.\n",
       "\n",
       "Agora, precisei traduzir isso para o português, explicando cada parte de forma clara e concisa. Devo destacar o role de yield from, dict comprehension e o if condition.\n",
       "\n",
       "Quero também garantir que a resposta Trades para que seja compreendida rapidamente. Talvez inclua um exemplo simplificado, como show authors de livros, para ilustrar o usso.\n",
       "</think>\n",
       "\n",
       "Este código gera uma sequência de autores de livros onde cada livro possui um campo \"author\". A expressão em dentro das parenteses serve de fonte para o operador `yield from`.\n",
       "\n",
       "Aqui está um exemplo simplificado:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Lídice\", \"author\": \"Antonio\"},\n",
       "    {\"title\": \"Música\", \"author\": None},\n",
       "    {\"title\": \"Setor Esportivo\", \"author\": \"Sergio\"}\n",
       "]\n",
       "\n",
       "autores = yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "O código irá:$\n",
       "- Iterar sobre cada dicionário (isbn) na lista `books`.\n",
       "- Obtém o valor do campo \"author\" para cada book.\n",
       "- Se o author não estiver em branco, adiciona ele à coleção que está sendo iterada.\n",
       "- Os resultados serão enviados para o converseiro usando yield from.\n",
       "\n",
       "O código é útil para recolher e processar individually os autores de livros onde o campo \"author\" é preenchido."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "\n",
    "stream = openai_ollama.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e3b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
